---
title: "Final Project"
author: "Cayla Pun"
output: html_notebook
date: December 14, 2020
---


```{r}
# loading libraries and "stop_words"
library(rvest)
library(tidyverse)
library(genius)
library(qdap)
library(tidytext)
library(mosaic)
library(lubridate)
library(esquisse)
data("stop_words")
```

```{r}
#read webpage for Grammy Awards
webpage <- read_html("https://en.wikipedia.org/wiki/Grammy_Award_for_Record_of_the_Year")
```


# **DATA PREP**

* 1980 data prep
```{r}

#regex to pull 1980 data
XPATH1980 <- '/html/body/div[3]/div[3]/div[5]/div[1]/table[5]' 

#creating table using regex
table_1980 <- 
  webpage %>%
  html_nodes(xpath = XPATH1980) %>%
  html_table(fill = TRUE)

#assigning table to data frame
D1980 <- table_1980[[1]]

#data wrangling: renaming columns, removing footnotes and na entries, creating a decade column
D1980 <- 
  D1980 %>% 
  drop_na() %>%
  rename(year = 'Year[I]', track = Record, artist = 'Artist(s)') %>% 
  mutate(year = gsub(pattern = "(\\[\\d+\\])", replacement = "", x = year)) %>% 
  mutate(decade = "1980s")

```


* 1990 data prep
```{r}
#regex to pull 1990 data
XPATH1990<-'/html/body/div[3]/div[3]/div[5]/div[1]/table[6]'

#creating table using regex
table_1990 <- 
  webpage %>%
  html_nodes(xpath = XPATH1990) %>%
  html_table(fill = TRUE)

#assigning table to data frame
D1990 <- table_1990[[1]]

#data wrangling: renaming columns, removing footnotes and na entries, creating a decade column
D1990 <- 
  D1990 %>% 
  drop_na() %>%
  rename(year = 'Year[I]', track = Record, artist = 'Artist(s)') %>% #removing header footnotes and renaming columns
  mutate(year = gsub(pattern = "(\\[\\d+\\])", replacement = "", x = year)) %>% #using hte gsub function to regex expression to remove footnotes from rows in year
  mutate(decade = "1990s") #creating the decacde column and defining its value
```


* 2000 data prep
```{r}
#regex to pull 2000 data
XPATH2000<- '/html/body/div[3]/div[3]/div[5]/div[1]/table[7]'

#creating table using regex
table_2000 <- 
  webpage %>%
  html_nodes(xpath = XPATH2000) %>%
  html_table(fill = TRUE)

#assigning table to data frame
D2000 <- table_2000[[1]]

#data wrangling: renaming columns, removing footnotes and na entries, creating a decade column
D2000 <- 
  D2000 %>% 
  drop_na() %>%
  rename(year = 'Year[I]', track = Record, artist = 'Artist(s)') %>%
  mutate(year = gsub(pattern = "(\\[\\d+\\])", replacement = "", x = year)) %>%
  mutate(decade = "2000s")
```


* 2010 data prep
```{r}
#regex to pull 2010 data
XPATH2010 <- '/html/body/div[3]/div[3]/div[5]/div[1]/table[8]'

#creating table using regex
table_2010 <- 
  webpage %>%
  html_nodes(xpath = XPATH2010) %>%
  html_table(fill = TRUE)

#assigning table to data frame
D2010 <- table_2010[[1]]

#data wrangling: renaming columns, removing footnotes and na entries, creating a decade column
D2010 <- 
  D2010 %>% 
  drop_na() %>%
  rename(year = 'Year[I]', track = Record, artist = 'Artist(s)') %>%
  mutate(year = gsub(pattern = "(\\[\\d+\\])", replacement = "", x = year)) %>%
  mutate(decade = "2010s")
```

#### For each decade, I had created a unique regular expression that would pull out the necessary decade information needed from the 'webpage.' I then created a table using that unique regex value and further assigned that table to a data frame. The data wrangling portion of the data frame included renaming columns, removing footnotes and entries that did not have a value (na), and creating a decade column. The function I used to remove the footnotes in each row of the year is gsub. The "gsub" function will replace all matches of a string. So the 'pattern' variable of gsub will look for that specific string or in this scenario, regular expression, and select that value. The next variable in the gsub function is 'replacement' and this is the string for replacement, and the last variable is 'x' and this is the column in which the gsub will search for the pattern and replace its matches. 

* all decades
```{r}
#data frame containing all decades
All <-
  D1980 %>%
  full_join(D1990) %>%
  full_join(D2000) %>%
  full_join(D2010)
```


* lyrics for all decades
```{r}
#adding lyrics
Alllyrics <- All %>% 
  add_genius(artist, track, type = "lyrics")

#lyrics before filtering out stop words and additional stop words
AllWords <-
  Alllyrics %>%
  unnest_tokens(word,lyric)

#removing stop words from all words
AllWords_stopwords <-
  AllWords %>%
  anti_join(stop_words, by = "word")

#removing additional stop words
AllWords_Final <-
  AllWords_stopwords %>%
  filter(word != 'ba', word != 'du',word != 'yeah',word != 'da',
         word != 'ya',word != 'ooh',word != 'gonna',word != 'na',
         word != 'uh',word != 'la',word !='hol') 
```

#### AllWords_Final is the final dataframe, words of each song with the stop words and additional words filtered out. The first dataframe created above, 'Alllyrics' is essentially creating a new column that is of type 'lyric.' The 'add_genius' function is specific towards artist and album/tracks and it creates the lyric column. The 'AllWords' data frame is splitting the lyrics column into 'tokens', in this case words, by using the 'unnnest_tokens' function and ensuring that each token has its own row. AllWords_stopwords is the dataframe in which the stop words were filtered out. This was done by using the 'anti_join' function and unmatching its values by the 'word' column. The last dataframe created 'AllWords_Final" uses the 'AllWords_stopwords' data frame and futher filters out the additional 11 words from the word column. 

# **GRAPHS**

#### 1. 

* data prep for graph 1
  + For this graph, my thought process was that I wanted to greate a dataframe that gathered and summed up the number of words per song. I used the 'AllWords' dataframe and created a new column called 'num' and assigned each value to the integer 1. This is to essentially add up the number of rows, which each had a single word, for each song. I then ensured that the decade column was of type character by using the mutate function and reassigning the decade column to be of type character by using 'as.character.' I then grouped by the necessary columns and used the summarise data verb to reassign the num column to the sum of the 1s. This gave me the number of words per song. I would then use this new dataframe and graph it by the decade variable and this will give me the words per song per decade. 

```{r}
#words per song dataframe ->idea adding every row and group by year
Wps <-
  AllWords %>%
  mutate(num = 1) %>% #assigning a 1 to every row
  mutate(decade = as.character(decade)) %>% #ensuring the decade is of type character
  group_by(track, decade, artist, year) %>% 
  summarise(num = sum(num)) %>% #adding up the number of words
  select(year, num, track, artist)

```

* graph: 
```{r}
ggplot(Wps) +
  aes(x = decade, y = num, fill = decade) +
  geom_boxplot() +
  scale_fill_brewer(palette = "BuPu") +
labs(x = "Words per Song", y = "Decade", title = "Boxplots of Words per Grammy Nominated Song by Decade ") +
  theme_minimal()
```

#### 2. 
* graph: 
  + My approach on this graph was pretty simple. I wanted to use the dataframe that filtered out all the stopwords and additional words. I then used the 'freq_terms' function to find the most frequently occurring terms in the 'word' column/vector. 
```{r}
Top_all <- freq_terms(AllWords_Final$word, 10, at.least=3) #top 10 words overall

ggplot(Top_all) +
  aes(x = reorder(WORD, desc(FREQ)), weight = FREQ) +
  geom_bar(fill = "#FF5733") +
  labs(x = "Word", y = "Count", title = "Ten Most Popular Words of Grammy Nominated Songs from 1980 - 2019") +
  theme_minimal()
```

#### 3.

* data prep for graph 3
  + My approach on this graph was to filter out the 'AllWords_Final' dataframe by decade and theng ather the most frequent terms from each decade. I will then create a unique graph for each dedcade and assign it to an object. In the end, after installing the necessary library, I used 'grid.arrange' to combine the object graph assigned with each of the four decades.
```{r}
#1980
Decade_1980 <-
  AllWords_Final %>%
  filter(decade == "1980s") 

Top10_1980 <- freq_terms(Decade_1980$word, 10, at.least=3)

g1 <- ggplot(Top10_1980) +
  aes(x = reorder(WORD, desc(FREQ)), weight = FREQ) +
  geom_bar(fill = "#ffe0ba") +
  labs(x = "Word", y = "Count", title = "1980s") +
  theme_minimal()


#1990
Decade_1990 <-
  AllWords_Final %>%
  filter(decade == "1990s")

Top10_1990 <- freq_terms(Decade_1990$word, 10, at.least=3)

g2 <- ggplot(Top10_1990) +
  aes(x = reorder(WORD, desc(FREQ)), weight = FREQ) +
  geom_bar(fill = "#d1f5b8") +
  labs(x = "Word", y = "Count", title = "1990s") +
  theme_minimal()


#2000
Decade_2000 <-
  AllWords_Final %>%
  filter(decade == "2000s")

Top10_2000 <- freq_terms(Decade_2000$word, 10, at.least=3)

g3 <- ggplot(Top10_2000) +
  aes(x = reorder(WORD, desc(FREQ)), weight = FREQ) +
  geom_bar(fill = "#b8d4f5") +
  labs(x = "Word", y = "Count", title = "2000s") +
  theme_minimal()


#2010
Decade_2010 <-
  AllWords_Final %>%
  filter(decade == "2010s")

Top10_2010 <- freq_terms(Decade_2010$word, 10, at.least=3)

g4 <- ggplot(Top10_2010) +
  aes(x = reorder(WORD, desc(FREQ)), weight = FREQ) +
  geom_bar(fill = "#c4c4ff") +
  labs(x = "Word", y = "Count", title = "2010s") +
  theme_minimal()
```
* graph: 
```{r}
#installing library needed to join graphs
library(gridExtra)

graph3 <- grid.arrange(g1, g2, g3,g4,
                             top="Top Ten Words by Decade",
                             ncol = 2, nrow = 2)
graph3
```


#### 4.
* data prep for graph 4
  + I first approached this graph/scenario by joining all of the words in each decade (using the previous dataframes created in the graph before) and assigned it to a new dataframe called 'WordSentiments.' I then used a left join with the table 'sentiments' to get the sentiments in the 'WordSentiments' dataframe. I used a left join because I wanted to keep all of the data in the 'left table' (WordSentiments), while also matching up the word sentiments that were given. There are a few words in 'WordSentiments' that were not assigned a sentiment from the 'sentiments' dataframe, so therefore I used 'drop_na' to remove the words that did not have a sentiment value. I then assigned the values in the sentiment column to an integer, if the word had a positive sentiment, it would be a 1, and if it was anegative sentiment, the value would be 0. I then reassigned the 'WordSentiments' dataframe and ensured that the sentiment column was of type integer by using 'as.integer' and also created a new column that would sum up the number of 1s and 0s to get the net sentiment value. 
```{r}
#combining decades
WordSentiments <-
  Decade_1980 %>%
  full_join(Decade_1990) %>%
  full_join(Decade_2000) %>%
  full_join(Decade_2010) 
#joining sentiments 
WordSentiments <-   
  left_join(WordSentiments, sentiments) %>% 
  drop_na()
#casting positive and negatives to 1 and 0
WordSentiments$sentiment[WordSentiments$sentiment == "positive"] <- 1
WordSentiments$sentiment[WordSentiments$sentiment == "negative"] <- 0
#creating and calculating net sentiment 
WordSentiments <-
  WordSentiments %>%
  group_by(year) %>%
  mutate(sentiment = as.integer(sentiment)) %>% 
  mutate(count = sum(sentiment))
```

* graph 4
```{r}
graph4 <- ggplot(WordSentiments) +
  aes(x = year, fill = decade, weight = count) +
  geom_bar() +
  scale_fill_brewer(palette = "BrBG") +
  labs(x = "Year", y = "Net Sentiment", title = "Net Sentiment Score by Year") +
  theme_minimal() 
graph4 <- graph4 + scale_x_discrete(breaks = c(1980,1990,2000,2010)) #creating breaks in the x axis

graph4
```

#### 5.
* data prep for graph 5
  + The dataprep for this graph was relatively simple. I had just used the same dataframe from the previous graph and created a new column called 'mean' which would find the mean of the sentiments. I also wanted to make sure that the decade column was of type character and did so by using 'as.character.' 
```{r}
MeanSentiments <-
  WordSentiments %>%
  mutate(deacde = as.character(decade)) %>% 
  group_by(decade) %>%
  mutate(mean = mean(sentiment)) #calculating the mean 
```

* graph 5
```{r}
graph5 <- ggplot(MeanSentiments) +
  aes(x = decade, fill = decade, group = decade, weight = mean) +
  geom_bar() +
  scale_fill_brewer(palette = "BuPu") +
  labs(x = "Decade", y = "Mean Sentiment Score", title = "Mean Sentiment Score by Decade") +
  theme_minimal()
graph5
```

#### 6.
  + The first block of code below is my data prep for graph 6. I essentially used the same dataframe as the previous two graphs and ensured that the year column was of type integer by using 'as.integer.' I then created a plot using ggplot and added a 'geom_smooth" to get the linear model fit line. In 'geom_smooth,' I used 'method' to ensure the type of line that I wanted, which is "lm" (stands for linear model) then I used 'color' to get the color of the line, 'se' was to remove confidence band that was surrounding the lineaer model, and 'fullrange' was used to ensure that the line went through the entire graph instead of having each decade with getting their own regression line. 
```{r}
WordSentiments <-
  WordSentiments %>%
  mutate(year = as.integer(year)) #changing the year variable to integer
  
graph6 <- ggplot(WordSentiments) +
  aes(x = year, y = count, colour = decade) +
  geom_point(size = 1L) +
  geom_smooth(method="lm",color = "black",se = FALSE, fullrange=TRUE) +
  scale_color_brewer(palette = "RdYlBu") +
  labs(x = "Year", y = "Net Sentiment", title = "Net Sentiment Score by Year of Grammy Nominated Records from 1980- 2019 with Linear Model Fit") +
  theme_minimal()
graph6
```

# **ZOOOM presentation link** [click here](https://psu.zoom.us/rec/play/WvP0aIVFm74B8jUkQ-gXbpLHDY2ofwZM9fGkMd3SaDWS8MQepCfjDo1jbBcoTWe3oxSfjevMC_euZfgj.dRqS57oPSHEYuX-S?startTime=1607932118000&_x_zm_rtaid=B1EIOCpNSfS0DZWUDVe0LQ.1607959366223.3b83876f543e324edb316fb3040568ea&_x_zm_rhtaid=331)